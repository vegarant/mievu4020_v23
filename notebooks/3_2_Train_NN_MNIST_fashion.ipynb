{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data and create dataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Dataset\n",
    "We can index Datasets manually like a list: `training_data[index]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img.shape:  torch.Size([1, 28, 28])\n",
      "img.dtype:  torch.float32\n",
      "img.device:  cpu\n",
      "im1.shape: torch.Size([28, 28])\n",
      "im2.shape:  torch.Size([28, 1, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "sample_idx = 104\n",
    "\n",
    "img, label = training_data[sample_idx]\n",
    "print('img.shape: ',  img.shape)\n",
    "print('img.dtype: ',  img.dtype)\n",
    "print('img.device: ', img.device) # Notice that the data is lying on the CPU. This is standard.\n",
    "\n",
    "im1 = img.squeeze()\n",
    "print('im1.shape:', im1.size())\n",
    "im2 = im1.unsqueeze(1)\n",
    "print('im2.shape: ', im2.shape)\n",
    "\n",
    "plt.title(labels_map[label], fontsize=20)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataloaders\n",
    "The `Dataset` retrieves our dataset’s features and labels one sample at a time. When training a model, we typically want to pass samples in “minibatches” and reshuffle the data at every epoch to reduce model overfitting and use Python’s `multiprocessing` to speed up data retrieval.\n",
    "\n",
    "`DataLoader` is an iterable that abstracts this complexity for us in an easy API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "shuffle=True\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=shuffle)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Iterate through the DataLoader\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAAD8CAYAAACM5bN4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOBUlEQVR4nO3da4wddRnH8d/T7bbbQkMvFLrYItTKpTStkgLWAKVUpLWCIETDRSEx9Y0Q0CBGUiuRFwrBIPrGF0TxQkMIiIJc5NIWLUrBgBrQAAVXCmW59MK2pUvb7d8XM6vLcub5d8+w7LPw/SQnpz3P+c/M2T2/zjnz9D9jKSUBiGfEUG8AgMYIJxAU4QSCIpxAUIQTCIpwAkERzg8oM+sws46h3g5UI5xNMLMWM1tqZg+Z2SYz22Vmr5rZP8zsBjM7fai3EcPfyKHegOHGzFok/V7SIklbJN0l6UVJoyQdJelcSUdIumOINhHvE4Rz4M5REcy/S5qfUnqjb9HMxko6big2DO8vfKwduE+W9zf2D6YkpZTeTCmt6v27mV1oZqm8X2Bmq81sq5l1mdldZnZko5WY2Vgz+7aZ/c3MtpvZNjP7i5md0+C5o8zsIjO728z+Y2ZvlR+3HzCzxQN5cWZ2bjn+X2Z2SJ/HjzCzG81svZntNLNXzGyFmR3eYBk3lq95upldXH7c32FmqweyLR907DkHbmN5f9gAx31W0uck3SPpp5JmSvqMpGPMbGZK6fXeJ5rZeEkrJX1c0uOSfqbiH9JTJa0ws6NSSsv6LHuipOsl/VnS/ZJek9Qu6TRJd5vZ0pTSDbkNNLPLJf2gXM7pKaVN5eOLJP1GUqukOyWtkzRV0uclLTGzBSmlxxss8npJJ6j46H+3pJ7cNqCPlBK3AdxUBGanpD2SfqXiDfph5/kXSkqSdkta2K/2/bJ2eb/Hb6x4vE3SveW6P9bn8dGSpjZY936SnpS0SdKYfrUOSR3ln0dI+km5ztsktfV53gRJmyW9Lmlmv2XMkrRN0uMV2/+SpEOH+nc2XG9DvgHD8SbpC5JeLt+AvbeNkm6XdFq/5/aG89cNlnNoWbu1z2OTyiA/VrHuOeWYa/ZyW79RPv/Efo93lLc2FXvFJOnHkkb0e94lZe1rFcu/rqzP7PNYbzgvGerf1XC+8bG2CSmlW8zsdkkLJB2vYm96vKQzJJ1hZr+UdGEq36mlvzZY1PryfkKfx46R1CIpmdmVDca0lvdv+65qZkdJ+qakE1V8pG3rN+5DDZY1RtKDkuZJ+lZK6ZoGz5lX3s+p2J7ej/dHSvpnv9qjDZ6PvUQ4m5RS2iXpvvLW22I5S8X3wy+r2Iv+ts+QLQ2WsdvMpCKMvSaV98eUtyr79v7BzD6h4jvqSBVhu0NSl8qPvyq+645usIxxko4un/uHivX0bs9SZ1vetj19dGbGwMHR2ndJSqknpXSLio95knRyk4vqPQJ8XUrJnNuCPmOWqdgLfjqltDildGlKaXlK6UpJa511variQFWrpFVmNtfZnjmZ7flFg7HM5K+BcL77tpb31uT4R1Xs8U4YwJgZkjallFY3qM33BqaUHlTRtx0p6QEzm9fvKY+U9wPZHrwLCOcAmdk5ZnaKmb3jZ2dmU/T/j39/bGb5KaVXJd0kaa6Zfaf8uNx/PR8xs0P7PNQhaaKZze73vK+oaL/k1vknSaeo2NPdZ2Z9A/1zFR/Jv2tmxzbYlhFmdlJuHRg4vnMO3HEqjmB2mtkaSf8uHz9U0hIVHy9/J+nWGuu4SNJHJX1P0pfK9bwi6SAVB16OUfE/lXrX/SMVIVxjZreo+Cg6V8VBqlslnZ1bYUpprZmdrKJPereZnZFSuj+ltNHMzlbxHfoRM3tQ0lMqgjxNxQGjSXrnASjURDgH7oeSnpX0KUmzVYSiTUUrZbWkFZJW9DtSOyAppa5y7/VVFf9X96xyHa+U6/66ihD1Pv9eMztNxXfPL6po9j+q4mjydO1FOMvlPFHuBR+QdKeZnZVSuiul9GC5V76sfL0nqOj1blBxIOq2Zl8rqlmN9xCAQcR3TiAowgkERTiBoAgnEJR7tNbMOFoEDLKUUsP/sMKeEwiKcAJBEU4gKMIJBEU4gaAIJxAU4QSCIpxAUIQTCIpwAkERTiAowgkERTiBoAgnEBThBIIinEBQhBMIinACQRFOICjCCQRFOIGgCCcQFOEEgiKcQFCEEwiKcAJBEU4gKMIJBEU4gaAIJxAU4QSCIpxAUIQTCIpwAkERTiAowgkERTiBoAgnEBThBIIinEBQhBMIinACQRFOICjCCQRFOIGgCCcQ1Mih3gC8f5x66qlu/aGHHnLr3d3dTa/bzJoeW3f5e/bsGZR1sucEgiKcQFCEEwiKcAJBEU4gKMIJBEUrpQkjR/o/tt27dze97BEj/H8vc4ft29vb3fr555/v1q+99trK2tVXX+2OXbhwoVvfvn27W7/iiisqa2vWrHHHppTcel2DvfxG2HMCQRFOICjCCQRFOIGgCCcQFOEEgiKcQFDm9W/M7L1v7gwDdfucLS0tlbWenh537MSJE936VVdd5dYnT57s1seNG1dZa21tdcfu2LHDrY8ePdqtz5o1q7L23HPPuWNXrFjh1vfff3+3nuvh7ty5063XkVJqOB+NPScQFOEEgiKcQFCEEwiKcAJBEU4gKMIJBEWfcwh4czZz8zVvuukmt77PPvu49a6uLrfu9UFzvcINGza49VGjRrn1OXPmVNbqvq4333zTrXd0dLj1zZs3V9Yuu+wyd+yLL77o1ulzAsMM4QSCIpxAUIQTCIpwAkERTiAowgkExXlrh0CdS8Y99thjbv3iiy9260899ZRb9+aivvzyy+7Y3Dl3c+fUnTRpUmUt1yvcsmWLW3/jjTfcem6u6cyZMytrU6ZMccfmtr0Ke04gKMIJBEU4gaAIJxAU4QSCIpxAUIQTCIo+ZzBr165167lz4ub6fYsXL3brDz/8cGXN60NK0owZM9x6W1ubW9+2bVtlzZtPuTf1XA/WrOGUyv/xzsnb3d3tjm0We04gKMIJBEU4gaAIJxAU4QSCIpxAUMO2lZI79O3xTgf6XjjvvPMqa08//bQ7dvz48W79tddec+tPPvmkWz/zzDMra7t27XLH5qZG5ba9s7Ozsua1WaT8lK9cPXdqTa8NdNJJJ7ljcz/zKuw5gaAIJxAU4QSCIpxAUIQTCIpwAkERTiCosH3O3OXicqeXzE2tqiM3dWrlypVu3etFPv/88+7Ye+65x60vWrTIred6lTfffHNlbdasWe7Yww8/3K3nTk/pXaavpaXFHZt7v4wc6b/Vc5cYHDt2bGXtoIMOcsc2iz0nEBThBIIinEBQhBMIinACQRFOICjCCQRl3txGM3MnPubmVHq9qcHsQ+ZMnz7drS9fvtytH3jggW4910tsbW2trOX6bTt37nTr48aNc+sbN2506968x8MOO8wd670uSXr22WfduifX58y9F3PzOXNzfL0+6gsvvOCOXbJkSW7dDTeePScQFOEEgiKcQFCEEwiKcAJBEU4gKMIJBOVOcsv1jnK9oTq9zH333detL1261K3Pnz+/srZ+/Xp3bN1zoObmcx5yyCGVtaOPPtodm5sTWXee67Rp0ypruT7mSy+95NZzvPdTrn+b6y339PTUGr99+/bKWq433Sz2nEBQhBMIinACQRFOICjCCQRFOIGgCCcQlNvnrHsdy2OPPbaydsEFF7hjc33OiRMnunVv3mLuvLPPPPOMWx8xwv83beHChW79gAMOqKw98cQT7tipU6e69TFjxrj1/fbbz63PmDGjsrZu3Tp3bK7Hmju3rNeDzfVYc+9Vr0+5N7z5pLmfebPYcwJBEU4gKMIJBEU4gaAIJxAU4QSCqnUJwGXLlrl175Jxmzdvdsd6l8mT/MvFSf6h9R07drhjvVaHlL+c3OTJk936qlWrKmsHH3ywO7auXAvKuwThtm3b3LG5KYZ1Thma+33X3bY60x9z0/ianVLGnhMIinACQRFOICjCCQRFOIGgCCcQFOEEgnIbdhMmTHAHz5492617077Gjh3rjt26datbz/Wtxo8fX1nbsGGDO3bLli1uPTf9KLd871J6udNu5nR3d7v1zs7Oppddp08p5afaeZc3zK27zuUopfy2ecvPve729na3XrlNTY0CMOgIJxAU4QSCIpxAUIQTCIpwAkERTiAo8+axmVmtc2POnTu3qZokzZs3z63nTrPozaHLncowd4rH3OXocnMPvb5YrmeW6+fl5Pp5dcbmfm65uteLzPU5vb62JL311ltuPXc61E2bNlXWcu/FSy+91K1v3bq14S+VPScQFOEEgiKcQFCEEwiKcAJBEU4gKMIJBOX2Odvb290+Z27OZd3Lrg2WXL8u1zNra2tz67nz4nrrr9tLzPVge3p63LrXR80tO/f7zs2p9LYt9zPt6upy67l5rnUvd1lHSok+JzCcEE4gKMIJBEU4gaAIJxAU4QSCclspLS0t7vHl3KkzvUPvdacX5Q7be4fec+0E73JvUv6we93LzeGdci2m3ClFc+PrTEHMXRIy1wbq7OyklQIMJ4QTCIpwAkERTiAowgkERTiBoAgnENSgnhrT6/flen25aVle30nyTzFZ9/SSdcfXMdg91lx/2VO3F+nxLg8o5XvTuZ9L7nV7y8+tO7ft3d3d9DmB4YRwAkERTiAowgkERTiBoAgnEBThBIIa1D4ngDxOjQkMM4QTCIpwAkERTiAowgkERTiBoAgnEBThBIIinEBQhBMIinACQRFOICjCCQRFOIGgCCcQFOEEgiKcQFCEEwiKcAJBEU4gKMIJBEU4gaAIJxAU4QSCIpxAUIQTCIpwAkERTiAowgkERTiBoAgnEBThBIIinEBQhBMIinACQRFOICjCCQRFOIGgLKU01NsAoAH2nEBQhBMIinACQRFOICjCCQRFOIGg/guwbQw8pAiyogAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 7\n"
     ]
    }
   ],
   "source": [
    "# Display image and label.\n",
    "train_input, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Input batch shape: {train_input.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_input[0].squeeze()\n",
    "label = int(train_labels[0])\n",
    "\n",
    "plt.title(labels_map[label], fontsize=20)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model\n",
    "We define our neural network by subclassing `nn.Module`, and initialize the neural network layers in `__init__`. Every `nn.Module` subclass implements the operations on input data in the forward method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(in_features=28*28, out_features=512, bias=True),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(in_features=512, out_features=256, bias=True),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(in_features=256, out_features=10, bias=True)\n",
    "    )\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (4): ReLU()\n",
       "  (5): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a few hyperparameters\n",
    "device = torch.device('cpu')\n",
    "epochs = 5 # Number of iterations with stochastic gradient descent.\n",
    "learning_rate = 0.003\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() # Define the loss funciton. It does not expect the input to be normalized\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # Choose the optimizer \n",
    "model.to(device) # Move model parameters to the device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the train loop\n",
    "\n",
    "Inside the training loop, optimization happens in three steps:\n",
    " * Call `optimizer.zero_grad()` to reset the gradients of model parameters. Gradients by default add up; to prevent double-counting, we explicitly zero them at each iteration.\n",
    " * Backpropagate the prediction loss with a call to `loss.backward()`. PyTorch deposits the gradients of the loss w.r.t. each parameter.\n",
    " * Once we have our gradients, we call `optimizer.step()` to adjust the parameters by the gradients collected in the backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    batch = 0\n",
    "    for x, y in dataloader:\n",
    "        # Compute prediction and loss\n",
    "        batch = batch + 1\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad() # A common mistake is to forget to call this function.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(x)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def validation_loop(dataloader, model, loss_fn, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    val_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            \n",
    "            val_loss += loss_fn(pred, y).item() # This is a float\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    val_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Validataion Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {val_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.281604  [ 6400/60000]\n",
      "loss: 2.241412  [12800/60000]\n",
      "loss: 2.195464  [19200/60000]\n",
      "loss: 2.132058  [25600/60000]\n",
      "loss: 2.063028  [32000/60000]\n",
      "loss: 2.002160  [38400/60000]\n",
      "loss: 1.856397  [44800/60000]\n",
      "loss: 1.718828  [51200/60000]\n",
      "loss: 1.605382  [57600/60000]\n",
      "Validataion Error: \n",
      " Accuracy: 61.9%, Avg loss: 1.615165 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.452635  [ 6400/60000]\n",
      "loss: 1.400475  [12800/60000]\n",
      "loss: 1.216873  [19200/60000]\n",
      "loss: 1.206285  [25600/60000]\n",
      "loss: 1.259416  [32000/60000]\n",
      "loss: 1.132978  [38400/60000]\n",
      "loss: 1.043663  [44800/60000]\n",
      "loss: 1.063684  [51200/60000]\n",
      "loss: 1.093651  [57600/60000]\n",
      "Validataion Error: \n",
      " Accuracy: 66.0%, Avg loss: 1.001456 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.997246  [ 6400/60000]\n",
      "loss: 0.957920  [12800/60000]\n",
      "loss: 1.149832  [19200/60000]\n",
      "loss: 0.988233  [25600/60000]\n",
      "loss: 0.944293  [32000/60000]\n",
      "loss: 0.922790  [38400/60000]\n",
      "loss: 0.918908  [44800/60000]\n",
      "loss: 0.735301  [51200/60000]\n",
      "loss: 1.011570  [57600/60000]\n",
      "Validataion Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.826030 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.782177  [ 6400/60000]\n",
      "loss: 0.749086  [12800/60000]\n",
      "loss: 0.916893  [19200/60000]\n",
      "loss: 0.726524  [25600/60000]\n",
      "loss: 0.599613  [32000/60000]\n",
      "loss: 0.582890  [38400/60000]\n",
      "loss: 0.749016  [44800/60000]\n",
      "loss: 0.629305  [51200/60000]\n",
      "loss: 0.683943  [57600/60000]\n",
      "Validataion Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.745005 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.610370  [ 6400/60000]\n",
      "loss: 0.749490  [12800/60000]\n",
      "loss: 0.785173  [19200/60000]\n",
      "loss: 0.464892  [25600/60000]\n",
      "loss: 0.691671  [32000/60000]\n",
      "loss: 0.728094  [38400/60000]\n",
      "loss: 0.727923  [44800/60000]\n",
      "loss: 0.529763  [51200/60000]\n",
      "loss: 0.564330  [57600/60000]\n",
      "Validataion Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.689735 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer, device)\n",
    "    validation_loop(test_dataloader, model, loss_fn, device)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
